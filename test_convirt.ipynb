{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d1 = pd.read_csv('/data/MIMIC-CXR/mimic-cxr-2.0.0-split.csv')\n",
    "d2 = pd.read_csv('/data/MIMIC-CXR/mimic_finding+impression2.csv')\n",
    "# print(d1)\n",
    "# print(d2)\n",
    "\n",
    "d3 = d1.merge(d2, on='subject_id', how='left')\n",
    "d3.drop_duplicates(subset=['dicom_id'], inplace=True)\n",
    "d3['dicom_id'] = d3['dicom_id'].apply(lambda x: x + '.jpg')\n",
    "d3.drop(columns=['impression'], inplace=True)\n",
    "d3.dropna(inplace=True)\n",
    "# print(d3)\n",
    "# d3.to_csv('CXR_paths_for_images_and_text.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image retrieval from text\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFile\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from train import SimCLR\n",
    "from models.model import ModelCLR\n",
    "from dataloader.dataset_wrapper import DataSetWrapper\n",
    "\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # transforms.RandomApply([color_jitter], p=0.8),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    # GaussianBlur(kernel_size=int(0.1 * self.input_shape[0])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ])\n",
    "\n",
    "candidate = pd.read_csv('../convirt/text-retrieval/candidate.csv')\n",
    "query = pd.read_csv('../convirt/text-retrieval/query.csv')\n",
    "features = query['Variable'].unique().tolist()\n",
    "img_root_dir = '/data/CheXpert/'\n",
    "\n",
    "all_images = []\n",
    "all_labels = []\n",
    "for idx in range(len(candidate)):\n",
    "    img_name = os.path.join(img_root_dir, candidate.iloc[idx, 0])\n",
    "    image = Image.open(img_name).convert('RGB')\n",
    "    all_images.append(data_transforms(image))\n",
    "    \n",
    "    one_hot = candidate.loc[idx, features].values.astype(int)\n",
    "    ind = np.where(one_hot==1)[0][0]\n",
    "    all_labels.append(features[ind])\n",
    "\n",
    "\n",
    "# =================== get image embeddings ===================\n",
    "config = yaml.load(open(\"config.yaml\", \"r\"), Loader=yaml.FullLoader)\n",
    "config['fine_tune_from'] = 'Apr16_10-42-55_sunlab-serv-03.cs.illinois.edu'\n",
    "dataset = DataSetWrapper(config['batch_size'], **config['dataset'])\n",
    "simclr = SimCLR(dataset, config)\n",
    "model = ModelCLR(**config[\"model\"]).to(\"cpu\")\n",
    "model = simclr._load_pre_trained_weights(model)\n",
    "\n",
    "image_embeddings = []\n",
    "for i in tqdm(range(len(all_images))):\n",
    "    image_embeddings.append(model.image_encoder(all_images[i].unsqueeze(0))[1])\n",
    "image_embeddings = torch.stack(image_embeddings)\n",
    "\n",
    "# =================== get text embeddings ===================\n",
    "tokenizer = AutoTokenizer.from_pretrained(config['model']['bert_base_model'])#, do_lower_case=config['model_bert']['do_lower_case'])\n",
    "text_embeddings = []\n",
    "for i in tqdm(range(len(query[\"Text\"]))):\n",
    "    text = query[\"Text\"].values[i]\n",
    "    tokens = tokenizer([text], \n",
    "                        return_tensors=\"pt\", \n",
    "                        padding=True, \n",
    "                        truncation=config['truncation'])\n",
    "    text_embeddings.append(model.text_encoder(tokens))\n",
    "text_embeddings = torch.cat(text_embeddings, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_embeddings.shape, image_embeddings.shape)\n",
    "cos = torch.matmul(text_embeddings, image_embeddings.T).detach().numpy()\n",
    "print(cos.shape)\n",
    "\n",
    "cos_sorted = cos.argsort(axis=1)[:,::-1]\n",
    "text_labels = query['Variable'].values\n",
    "p_a_k5 = []\n",
    "p_a_k10 = []\n",
    "p_a_k50 = []\n",
    "\n",
    "for i in range(0,40):\n",
    "    preds = cos_sorted[i]\n",
    "    hits = np.array([all_labels[pred]==text_labels[i] for pred in preds])\n",
    "    p_a_k5.append(hits[:5].sum()/5)\n",
    "    p_a_k10.append(hits[:10].sum()/10)\n",
    "    p_a_k50.append(hits[:50].sum()/50)\n",
    "    print(\"p@5 {} p@10 {} p@50 {}\".format(p_a_k5[-1], p_a_k10[-1], p_a_k50[-1]))\n",
    "\n",
    "print(\"p@5 {} p@10 {} p@p@50 {}\".format(np.mean(p_a_k5), np.mean(p_a_k10), np.mean(p_a_k50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image retrieval from images\n",
    "candidate = pd.read_csv('../convirt/image-retrieval/candidate.csv')\n",
    "query = pd.read_csv('../convirt/image-retrieval/query.csv')\n",
    "features = query['Variable'].unique().tolist()\n",
    "img_root_dir = '/data/CheXpert/'\n",
    "\n",
    "query_images = []\n",
    "for idx in range(len(query)):\n",
    "    img_name = os.path.join(img_root_dir, query.iloc[idx, 1])\n",
    "    image = Image.open(img_name).convert('RGB')\n",
    "    query_images.append(data_transforms(image))\n",
    "    \n",
    "\n",
    "# =================== get image embeddings ===================\n",
    "query_image_embeddings = []\n",
    "for i in tqdm(range(len(query_images))):\n",
    "    query_image_embeddings.append(model.image_encoder(query_images[i].unsqueeze(0))[1])\n",
    "query_image_embeddings = torch.stack(query_image_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(query_image_embeddings.shape, image_embeddings.shape)\n",
    "cos = torch.matmul(query_image_embeddings, image_embeddings.T).detach().numpy()\n",
    "print(cos.shape)\n",
    "\n",
    "cos_sorted = cos.argsort(axis=1)[:,::-1]\n",
    "text_labels = query['Variable'].values\n",
    "p_a_k5 = []\n",
    "p_a_k10 = []\n",
    "p_a_k50 = []\n",
    "\n",
    "for i in range(0,40):\n",
    "    preds = cos_sorted[i]\n",
    "    hits = np.array([all_labels[pred]==text_labels[i] for pred in preds])\n",
    "    p_a_k5.append(hits[:5].sum()/5)\n",
    "    p_a_k10.append(hits[:10].sum()/10)\n",
    "    p_a_k50.append(hits[:50].sum()/50)\n",
    "    print(\"p@5 {} p@10 {} p@50 {}\".format(p_a_k5[-1], p_a_k10[-1], p_a_k50[-1]))\n",
    "\n",
    "print(\"p@5 {} p@10 {} p@p@50 {}\".format(np.mean(p_a_k5), np.mean(p_a_k10), np.mean(p_a_k50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, RocCurveDisplay, auc, roc_curve\n",
    "\n",
    "def auc_scorer(estimator, X, y):\n",
    "    y_pred = estimator.predict_proba(X)\n",
    "    return roc_auc_score(y, y_pred, multi_class='ovr')\n",
    "\n",
    "\n",
    "X = image_embeddings.detach().numpy()\n",
    "y = np.array(all_labels)\n",
    "classifier = LogisticRegression(random_state=0, max_iter=1000)\n",
    "\n",
    "cross_val_score(classifier, X, y, cv=5, scoring=auc_scorer).mean()\n",
    "# cv = StratifiedKFold(n_splits=5)\n",
    "# tprs = []\n",
    "# aucs = []\n",
    "# mean_fpr = np.linspace(0, 1, 100)\n",
    "# # fig, ax = plt.subplots(figsize=(6, 6))\n",
    "# for fold, (train, test) in enumerate(cv.split(X, y)):\n",
    "#     classifier.fit(X[train], y[train])\n",
    "#     pred = classifier.predict_proba(X[test])\n",
    "#     fpr, tpr, thresholds = roc_curve(y, pred)\n",
    "#     roc_auc = auc(fpr, tpr)\n",
    "#     interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "\n",
    "#     interp_tpr[0] = 0.0\n",
    "#     tprs.append(interp_tpr)\n",
    "#     aucs.append(roc_auc)\n",
    "# # ax.plot([0, 1], [0, 1], \"k--\", label=\"chance level (AUC = 0.5)\")\n",
    "\n",
    "# mean_tpr = np.mean(tprs, axis=0)\n",
    "# mean_tpr[-1] = 1.0\n",
    "# mean_auc = auc(mean_fpr, mean_tpr)\n",
    "# print(mean_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl4h",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
